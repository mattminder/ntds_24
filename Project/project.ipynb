{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import scipy.sparse.linalg\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.measure.pairwise import pairwise_kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load directed adjacency matrix\n",
    "dir_adj = np.load(DATA_FOLDER + 'dir_adj_matrix.npy')\n",
    "lc_index = np.load(DATA_FOLDER + 'largest_component_ix.npy')\n",
    "dir_adj = dir_adj[lc_index, :][:,lc_index]\n",
    "n_nodes = dir_adj[0]\n",
    "\n",
    "# Load metadata\n",
    "meta = pd.read_csv(DATA_FOLDER + 'categories.tsv', \n",
    "                   sep='\\t', encoding='UTF-8', engine='python', comment='#', header=None)\n",
    "meta.columns = ['Site','FullCategory']\n",
    "meta = meta.iloc[lc_index]\n",
    "\n",
    "# Extract top category\n",
    "categories_re = np.copy(meta['FullCategory'])\n",
    "for i in range(categories_re.size):\n",
    "    tmp = categories_re[i]\n",
    "    tmp = re.sub('subject.', '', tmp)\n",
    "    tmp = re.sub('\\..*', '', tmp)\n",
    "    categories_re[i] = tmp\n",
    "\n",
    "meta['TopCategory'] = categories_re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbor Graph Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k Nearest Neighbors Construction\n",
    "In the following, we infer the network based on the k-nearest-neighbors method. Thereby, every node is connected to the $k$ nearest neighbors in the space of our previously extracted keywords. $k$ is chosen to be the average degree of our original network, in order for the constructed network to be comparable to the original network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def degree_distribution(adj):\n",
    "    \"\"\"Computes the degree distribution\n",
    "    Params:\n",
    "    adj: (directed) adjacency matrix\n",
    "\n",
    "    Returns:\n",
    "    a matrix with 2 columns, [in_degree, out_degree]\n",
    "    \"\"\"\n",
    "    in_degree = np.matmul(adj.T,np.ones((adj.shape[1],1)))\n",
    "    out_degree = np.matmul(adj,np.ones((adj.shape[0],1)))\n",
    "    return in_degree, out_degree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_degree, out_degree = degree_distribution(dir_adj)\n",
    "avg_degree = in_degree.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_adj = kneighbors_graph(X, \n",
    "                           n_neighbors=avg_deg,    # I propose taking as many neighbors as is the avg deg\n",
    "                           mode='connectivity',    # Return unweighted adjacency matrix\n",
    "                           p=2,                    # Euclidian distance metric\n",
    "                           n_jobs=-1               # Use all processors\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel based graph construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we construct a graph based on a kernel based distance measure: If the distance measure between two nodes is below a certain threshold, they are connected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_graph_construction(X,  \n",
    "                              metric='linear', cutoff=None, avg_deg=10, **kwds):\n",
    "    pw_kernels = pairwise_kernels(X, metric=metric, **kwds)\n",
    "    # TODO: Implement automatic cutoff detection\n",
    "    out = [1 if i<=cutoff else 0 for i in pw_kernels]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pagerank applied to wikipedia articles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_rank(A,E,eps,maxit):\n",
    "    '''\n",
    "    A: Transition matrix of the graph (sparse)\n",
    "    E: Random Surfer probabilities\n",
    "    eps: stopping criterion ||R_new-R_old||1<eps\n",
    "    maxit: maximum number of iterations   \n",
    "    '''\n",
    "    R = E\n",
    "    maxit_stop = True\n",
    "    for i in range(maxit):\n",
    "        R_new = A.dot(E)\n",
    "        d = np.linalg.norm(R_new,ord=1) - np.linalg.norm(R,ord=1)\n",
    "        R_new = R_new + d*E\n",
    "        if(np.linalg.norm(R_new-R)<eps):\n",
    "            maxit_stop = false\n",
    "    if(maxit_stop):\n",
    "        print('Stopped due to maximum iteration condition')\n",
    "    else:\n",
    "        print('Stopped due to epsilon condition')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
