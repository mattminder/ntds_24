{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import scipy.sparse.linalg\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load directed adjacency matrix\n",
    "dir_adj = np.load(DATA_FOLDER + 'dir_adj_matrix.npy')\n",
    "lc_index = np.load(DATA_FOLDER + 'largest_component_ix.npy')\n",
    "dir_adj = dir_adj[lc_index, :][:,lc_index]\n",
    "\n",
    "# Load metadata\n",
    "meta = pd.read_csv(DATA_FOLDER + 'categories.tsv', \n",
    "                   sep='\\t', encoding='UTF-8', engine='python', comment='#', header=None)\n",
    "meta.columns = ['Site','FullCategory']\n",
    "meta = meta.iloc[lc_index]\n",
    "\n",
    "# Extract top category\n",
    "categories_re = np.copy(meta['FullCategory'])\n",
    "for i in range(categories_re.size):\n",
    "    tmp = categories_re[i]\n",
    "    tmp = re.sub('subject.', '', tmp)\n",
    "    tmp = re.sub('\\..*', '', tmp)\n",
    "    categories_re[i] = tmp\n",
    "\n",
    "#unique_top_categories = np.unique(categories_re)\n",
    "#n_cat = unique_categories.size\n",
    "\n",
    "meta['TopCategory'] = categories_re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pagerank applied to wikipedia articles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_rank(A,E,eps,maxit):\n",
    "    '''\n",
    "    A: Transition matrix of the graph (sparse)\n",
    "    E: Random Surfer probabilities\n",
    "    eps: stopping criterion ||R_new-R_old||1<eps\n",
    "    maxit: maximum number of iterations   \n",
    "    '''\n",
    "    R = E\n",
    "    maxit_stop = True\n",
    "    for i in range(maxit):\n",
    "        R_new = A.dot(E)\n",
    "        d = np.linalg.norm(R_new,ord=1) - np.linalg.norm(R,ord=1)\n",
    "        R_new = R_new + d*E\n",
    "        if(np.linalg.norm(R_new-R)<eps):\n",
    "            maxit_stop = false\n",
    "    if(maxit_stop):\n",
    "        print('Stopped due to maximum iteration condition')\n",
    "    else:\n",
    "        print('Stopped due to epsilon condition')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
